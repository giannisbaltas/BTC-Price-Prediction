{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d3f1dff",
   "metadata": {},
   "source": [
    "### Importing Needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5411084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.optimize as opt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a67abca",
   "metadata": {},
   "source": [
    "### Reading the Data in\n",
    "The last 5 years given by Yahoo Finance are from 09/11/2017 to Present(29/12/2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dc3c1e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-11-09</td>\n",
       "      <td>7446.830078</td>\n",
       "      <td>7446.830078</td>\n",
       "      <td>7101.520020</td>\n",
       "      <td>7143.580078</td>\n",
       "      <td>7143.580078</td>\n",
       "      <td>3226249984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-11-10</td>\n",
       "      <td>7173.729980</td>\n",
       "      <td>7312.000000</td>\n",
       "      <td>6436.870117</td>\n",
       "      <td>6618.140137</td>\n",
       "      <td>6618.140137</td>\n",
       "      <td>5208249856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-11-11</td>\n",
       "      <td>6618.609863</td>\n",
       "      <td>6873.149902</td>\n",
       "      <td>6204.220215</td>\n",
       "      <td>6357.600098</td>\n",
       "      <td>6357.600098</td>\n",
       "      <td>4908680192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-11-12</td>\n",
       "      <td>6295.450195</td>\n",
       "      <td>6625.049805</td>\n",
       "      <td>5519.009766</td>\n",
       "      <td>5950.069824</td>\n",
       "      <td>5950.069824</td>\n",
       "      <td>8957349888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-13</td>\n",
       "      <td>5938.250000</td>\n",
       "      <td>6811.189941</td>\n",
       "      <td>5844.290039</td>\n",
       "      <td>6559.490234</td>\n",
       "      <td>6559.490234</td>\n",
       "      <td>6263249920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>2021-12-25</td>\n",
       "      <td>50854.917969</td>\n",
       "      <td>51176.597656</td>\n",
       "      <td>50236.707031</td>\n",
       "      <td>50429.859375</td>\n",
       "      <td>50429.859375</td>\n",
       "      <td>19030650914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>2021-12-26</td>\n",
       "      <td>50428.691406</td>\n",
       "      <td>51196.378906</td>\n",
       "      <td>49623.105469</td>\n",
       "      <td>50809.515625</td>\n",
       "      <td>50809.515625</td>\n",
       "      <td>20964372926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>50802.609375</td>\n",
       "      <td>51956.328125</td>\n",
       "      <td>50499.468750</td>\n",
       "      <td>50640.417969</td>\n",
       "      <td>50640.417969</td>\n",
       "      <td>24324345758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>50679.859375</td>\n",
       "      <td>50679.859375</td>\n",
       "      <td>47414.210938</td>\n",
       "      <td>47588.855469</td>\n",
       "      <td>47588.855469</td>\n",
       "      <td>33430376883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>47576.855469</td>\n",
       "      <td>48101.585938</td>\n",
       "      <td>46730.207031</td>\n",
       "      <td>46854.156250</td>\n",
       "      <td>46854.156250</td>\n",
       "      <td>30502799360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1512 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date          Open          High           Low         Close  \\\n",
       "0     2017-11-09   7446.830078   7446.830078   7101.520020   7143.580078   \n",
       "1     2017-11-10   7173.729980   7312.000000   6436.870117   6618.140137   \n",
       "2     2017-11-11   6618.609863   6873.149902   6204.220215   6357.600098   \n",
       "3     2017-11-12   6295.450195   6625.049805   5519.009766   5950.069824   \n",
       "4     2017-11-13   5938.250000   6811.189941   5844.290039   6559.490234   \n",
       "...          ...           ...           ...           ...           ...   \n",
       "1507  2021-12-25  50854.917969  51176.597656  50236.707031  50429.859375   \n",
       "1508  2021-12-26  50428.691406  51196.378906  49623.105469  50809.515625   \n",
       "1509  2021-12-27  50802.609375  51956.328125  50499.468750  50640.417969   \n",
       "1510  2021-12-28  50679.859375  50679.859375  47414.210938  47588.855469   \n",
       "1511  2021-12-29  47576.855469  48101.585938  46730.207031  46854.156250   \n",
       "\n",
       "         Adj Close       Volume  \n",
       "0      7143.580078   3226249984  \n",
       "1      6618.140137   5208249856  \n",
       "2      6357.600098   4908680192  \n",
       "3      5950.069824   8957349888  \n",
       "4      6559.490234   6263249920  \n",
       "...            ...          ...  \n",
       "1507  50429.859375  19030650914  \n",
       "1508  50809.515625  20964372926  \n",
       "1509  50640.417969  24324345758  \n",
       "1510  47588.855469  33430376883  \n",
       "1511  46854.156250  30502799360  \n",
       "\n",
       "[1512 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"btc-usd.csv\")\n",
    "\n",
    "# take a look at the dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe0382a",
   "metadata": {},
   "source": [
    "### Data pre-processing and selection\n",
    "Let's create a new collumn which is responsible for the prediction. 0 if the Close value is higher than the previous day or 1 if it's not.\n",
    "Firstly is 0 in all rows and after pre-processing it will be changed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d7a3492",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Binary_Closed'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0fbe8a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " # True if close value is greater than the close value of the previous day\n",
    "df['Binary_Closed'] = df.Close > df.Close.shift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d647b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Binary_Closed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-11-09</td>\n",
       "      <td>7446.830078</td>\n",
       "      <td>7446.830078</td>\n",
       "      <td>7101.520020</td>\n",
       "      <td>7143.580078</td>\n",
       "      <td>7143.580078</td>\n",
       "      <td>3226249984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-11-10</td>\n",
       "      <td>7173.729980</td>\n",
       "      <td>7312.000000</td>\n",
       "      <td>6436.870117</td>\n",
       "      <td>6618.140137</td>\n",
       "      <td>6618.140137</td>\n",
       "      <td>5208249856</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-11-11</td>\n",
       "      <td>6618.609863</td>\n",
       "      <td>6873.149902</td>\n",
       "      <td>6204.220215</td>\n",
       "      <td>6357.600098</td>\n",
       "      <td>6357.600098</td>\n",
       "      <td>4908680192</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-11-12</td>\n",
       "      <td>6295.450195</td>\n",
       "      <td>6625.049805</td>\n",
       "      <td>5519.009766</td>\n",
       "      <td>5950.069824</td>\n",
       "      <td>5950.069824</td>\n",
       "      <td>8957349888</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-13</td>\n",
       "      <td>5938.250000</td>\n",
       "      <td>6811.189941</td>\n",
       "      <td>5844.290039</td>\n",
       "      <td>6559.490234</td>\n",
       "      <td>6559.490234</td>\n",
       "      <td>6263249920</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>2021-12-25</td>\n",
       "      <td>50854.917969</td>\n",
       "      <td>51176.597656</td>\n",
       "      <td>50236.707031</td>\n",
       "      <td>50429.859375</td>\n",
       "      <td>50429.859375</td>\n",
       "      <td>19030650914</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>2021-12-26</td>\n",
       "      <td>50428.691406</td>\n",
       "      <td>51196.378906</td>\n",
       "      <td>49623.105469</td>\n",
       "      <td>50809.515625</td>\n",
       "      <td>50809.515625</td>\n",
       "      <td>20964372926</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>50802.609375</td>\n",
       "      <td>51956.328125</td>\n",
       "      <td>50499.468750</td>\n",
       "      <td>50640.417969</td>\n",
       "      <td>50640.417969</td>\n",
       "      <td>24324345758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>50679.859375</td>\n",
       "      <td>50679.859375</td>\n",
       "      <td>47414.210938</td>\n",
       "      <td>47588.855469</td>\n",
       "      <td>47588.855469</td>\n",
       "      <td>33430376883</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>47576.855469</td>\n",
       "      <td>48101.585938</td>\n",
       "      <td>46730.207031</td>\n",
       "      <td>46854.156250</td>\n",
       "      <td>46854.156250</td>\n",
       "      <td>30502799360</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1512 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date          Open          High           Low         Close  \\\n",
       "0     2017-11-09   7446.830078   7446.830078   7101.520020   7143.580078   \n",
       "1     2017-11-10   7173.729980   7312.000000   6436.870117   6618.140137   \n",
       "2     2017-11-11   6618.609863   6873.149902   6204.220215   6357.600098   \n",
       "3     2017-11-12   6295.450195   6625.049805   5519.009766   5950.069824   \n",
       "4     2017-11-13   5938.250000   6811.189941   5844.290039   6559.490234   \n",
       "...          ...           ...           ...           ...           ...   \n",
       "1507  2021-12-25  50854.917969  51176.597656  50236.707031  50429.859375   \n",
       "1508  2021-12-26  50428.691406  51196.378906  49623.105469  50809.515625   \n",
       "1509  2021-12-27  50802.609375  51956.328125  50499.468750  50640.417969   \n",
       "1510  2021-12-28  50679.859375  50679.859375  47414.210938  47588.855469   \n",
       "1511  2021-12-29  47576.855469  48101.585938  46730.207031  46854.156250   \n",
       "\n",
       "         Adj Close       Volume  Binary_Closed  \n",
       "0      7143.580078   3226249984              0  \n",
       "1      6618.140137   5208249856              0  \n",
       "2      6357.600098   4908680192              0  \n",
       "3      5950.069824   8957349888              0  \n",
       "4      6559.490234   6263249920              1  \n",
       "...            ...          ...            ...  \n",
       "1507  50429.859375  19030650914              0  \n",
       "1508  50809.515625  20964372926              1  \n",
       "1509  50640.417969  24324345758              0  \n",
       "1510  47588.855469  33430376883              0  \n",
       "1511  46854.156250  30502799360              0  \n",
       "\n",
       "[1512 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Binary_Closed'] = df['Binary_Closed'].astype(int)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d9a249b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Binary_Closed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7446.830078</td>\n",
       "      <td>7446.830078</td>\n",
       "      <td>7101.520020</td>\n",
       "      <td>7143.580078</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7173.729980</td>\n",
       "      <td>7312.000000</td>\n",
       "      <td>6436.870117</td>\n",
       "      <td>6618.140137</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6618.609863</td>\n",
       "      <td>6873.149902</td>\n",
       "      <td>6204.220215</td>\n",
       "      <td>6357.600098</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6295.450195</td>\n",
       "      <td>6625.049805</td>\n",
       "      <td>5519.009766</td>\n",
       "      <td>5950.069824</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5938.250000</td>\n",
       "      <td>6811.189941</td>\n",
       "      <td>5844.290039</td>\n",
       "      <td>6559.490234</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6561.479980</td>\n",
       "      <td>6764.979980</td>\n",
       "      <td>6461.750000</td>\n",
       "      <td>6635.750000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6634.759766</td>\n",
       "      <td>7342.250000</td>\n",
       "      <td>6634.759766</td>\n",
       "      <td>7315.540039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7323.240234</td>\n",
       "      <td>7967.379883</td>\n",
       "      <td>7176.580078</td>\n",
       "      <td>7871.689941</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7853.569824</td>\n",
       "      <td>8004.589844</td>\n",
       "      <td>7561.089844</td>\n",
       "      <td>7708.990234</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7697.209961</td>\n",
       "      <td>7884.990234</td>\n",
       "      <td>7463.439941</td>\n",
       "      <td>7790.149902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7766.029785</td>\n",
       "      <td>8101.910156</td>\n",
       "      <td>7694.100098</td>\n",
       "      <td>8036.490234</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8039.069824</td>\n",
       "      <td>8336.860352</td>\n",
       "      <td>7949.359863</td>\n",
       "      <td>8200.639648</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8205.740234</td>\n",
       "      <td>8348.660156</td>\n",
       "      <td>7762.709961</td>\n",
       "      <td>8071.259766</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8077.950195</td>\n",
       "      <td>8302.259766</td>\n",
       "      <td>8075.470215</td>\n",
       "      <td>8253.549805</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8232.379883</td>\n",
       "      <td>8267.400391</td>\n",
       "      <td>8038.770020</td>\n",
       "      <td>8038.770020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Open         High          Low        Close  Binary_Closed\n",
       "0   7446.830078  7446.830078  7101.520020  7143.580078              0\n",
       "1   7173.729980  7312.000000  6436.870117  6618.140137              0\n",
       "2   6618.609863  6873.149902  6204.220215  6357.600098              0\n",
       "3   6295.450195  6625.049805  5519.009766  5950.069824              0\n",
       "4   5938.250000  6811.189941  5844.290039  6559.490234              1\n",
       "5   6561.479980  6764.979980  6461.750000  6635.750000              1\n",
       "6   6634.759766  7342.250000  6634.759766  7315.540039              1\n",
       "7   7323.240234  7967.379883  7176.580078  7871.689941              1\n",
       "8   7853.569824  8004.589844  7561.089844  7708.990234              0\n",
       "9   7697.209961  7884.990234  7463.439941  7790.149902              1\n",
       "10  7766.029785  8101.910156  7694.100098  8036.490234              1\n",
       "11  8039.069824  8336.860352  7949.359863  8200.639648              1\n",
       "12  8205.740234  8348.660156  7762.709961  8071.259766              0\n",
       "13  8077.950195  8302.259766  8075.470215  8253.549805              1\n",
       "14  8232.379883  8267.400391  8038.770020  8038.770020              0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf = df[['Open','High','Low','Close','Binary_Closed']]\n",
    "cdf.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ced42f",
   "metadata": {},
   "source": [
    "Let's define X, and y for our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4791d6e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7446.830078, 7446.830078, 7101.52002 ],\n",
       "       [7173.72998 , 7312.      , 6436.870117],\n",
       "       [6618.609863, 6873.149902, 6204.220215],\n",
       "       [6295.450195, 6625.049805, 5519.009766],\n",
       "       [5938.25    , 6811.189941, 5844.290039]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.asarray(cdf[['Open','High','Low']])\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83632257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.asarray(cdf.Binary_Closed)\n",
    "y[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa53e3b",
   "metadata": {},
   "source": [
    "Also, we normalize the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24bb12e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06546927, 0.06367244, 0.06187956],\n",
       "       [0.06122288, 0.06161442, 0.05136141],\n",
       "       [0.0525914 , 0.05491587, 0.0476797 ],\n",
       "       [0.04756665, 0.05112891, 0.03683618],\n",
       "       [0.0420126 , 0.05397012, 0.04198377]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = MinMaxScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa67e27",
   "metadata": {},
   "source": [
    "### Train/Test dataset\n",
    "We split our dataset into train and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99b397ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (1209, 3) (1209,)\n",
      "Test set: (303, 3) (303,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be9772cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LogisticRegression().fit(X_train,y_train)\n",
    "LR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d7ec11",
   "metadata": {},
   "source": [
    "Now we can predict using our test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47ac3db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = LR.predict(X_test)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd72cc4b",
   "metadata": {},
   "source": [
    "**predict_proba**  returns estimates for all classes, ordered by the label of classes. So, the first column is the probability of class 0, P(Y=0|X), and second column is probability of class 1, P(Y=1|X):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67b81c18",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.47266484, 0.52733516],\n",
       "       [0.47187615, 0.52812385],\n",
       "       [0.47207196, 0.52792804],\n",
       "       [0.47660154, 0.52339846],\n",
       "       [0.4717068 , 0.5282932 ],\n",
       "       [0.47522832, 0.52477168],\n",
       "       [0.47099138, 0.52900862],\n",
       "       [0.47149669, 0.52850331],\n",
       "       [0.47385193, 0.52614807],\n",
       "       [0.47098148, 0.52901852],\n",
       "       [0.47201443, 0.52798557],\n",
       "       [0.46019424, 0.53980576],\n",
       "       [0.48028457, 0.51971543],\n",
       "       [0.47151587, 0.52848413],\n",
       "       [0.46749481, 0.53250519],\n",
       "       [0.46897287, 0.53102713],\n",
       "       [0.47047208, 0.52952792],\n",
       "       [0.4687522 , 0.5312478 ],\n",
       "       [0.47131428, 0.52868572],\n",
       "       [0.47116806, 0.52883194],\n",
       "       [0.48126169, 0.51873831],\n",
       "       [0.47938872, 0.52061128],\n",
       "       [0.47074802, 0.52925198],\n",
       "       [0.4803152 , 0.5196848 ],\n",
       "       [0.46964385, 0.53035615],\n",
       "       [0.47545778, 0.52454222],\n",
       "       [0.47772064, 0.52227936],\n",
       "       [0.47238461, 0.52761539],\n",
       "       [0.46910794, 0.53089206],\n",
       "       [0.47091665, 0.52908335]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_prob = LR.predict_proba(X_test)\n",
    "y_predicted_prob[0:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef92ff1",
   "metadata": {},
   "source": [
    "### Jaccard Index\n",
    "\n",
    "Let's try the jaccard index for accuracy evaluation. we can define jaccard as the size of the intersection divided by the size of the union of the two label sets. If the entire set of predicted labels for a sample strictly matches with the true set of labels, then the subset accuracy is 1.0; otherwise it is 0.0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44da7414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02142857142857143"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "jaccard_score(y_test, y_predicted,pos_label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "029e6007",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.02      0.04       140\n",
      "           1       0.54      1.00      0.70       163\n",
      "\n",
      "    accuracy                           0.55       303\n",
      "   macro avg       0.77      0.51      0.37       303\n",
      "weighted avg       0.75      0.55      0.40       303\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "matrix = confusion_matrix(y_test, y_predicted)\n",
    "sns.heatmap(matrix, annot=True, fmt=\"d\", cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff0dff5",
   "metadata": {},
   "source": [
    "Let's look at first row. The first row is for values whose actual binary_closed value in the test set is 0. As you can calculate, out of 303 values, the binary_closed value of 140 of them is 0. Out of these 140 cases, the classifier correctly predicted 3 of them as 0, and 137 of them as 1.\n",
    "\n",
    "At the second row it looks like there were 163 values whom their binary_closed value were 1. The classifier correctly predicted all of them as 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7490df33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "023a4032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5478547854785478\n",
      "Precision: 0.5433333333333333\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",accuracy_score(y_test, y_predicted))\n",
    "print(\"Precision:\",precision_score(y_test, y_predicted))\n",
    "print(\"Recall:\",recall_score(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c391c9ab",
   "metadata": {},
   "source": [
    "### Log Loss\n",
    "Now, let's try log loss for evaluation. In logistic regression, the output can be the probability of a Close value to be higher than this one of the previous day is True (or equals to 1). This probability is a value between 0 and 1. Log loss( Logarithmic loss) measures the performance of a classifier where the predicted output is a probability value between 0 and 1. \n",
    "A Lower log loss value means better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41aa10f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6856324823313277"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "log_loss(y_test, y_predicted_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d73c419",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
